---
document_id: flink_how-to-guides_deduplicate-rows_chunk_2
source_file: flink_how-to-guides_deduplicate-rows.md
source_url: https://docs.confluent.io/cloud/current/flink/how-to-guides/deduplicate-rows.html
title: Deduplicate Rows in a Table with Confluent Cloud for Apache Flink
chunk_index: 2
total_chunks: 2
---

Region_3 Zee 1677260922 female Region_5

## Step 2: Apply the Deduplicate Topic action¶

In the previous step, you created a Flink table that had duplicate rows. In this step, you apply the Deduplicate Topic action to create an output table that has only unique rows.

  1. In the navigation menu, click **Data portal**.

  2. In the **Data portal** page, click the **Environment** dropdown menu and select the environment for your workspace.

  3. In the **Recently created** section, find your **users** topic and click it to open the details pane.

  4. Click **Actions** , and in the Actions list, click **Deduplicate topic** to open the **Deduplicate topic** dialog.

  5. In the **Fields to deduplicate** dropdown, select **user_id**.

Flink uses the deduplication field as the output message key. This means that the output topic’s row key may be different from the input topic’s row key, because the deduplication statement’s DISTRIBUTED BY clause determines the output topic’s key.

For this example, the output message key is the `user_id` field.

  6. In the **Compute pool** dropdown, select the compute pool you want to use.

  7. (Optional) In the **Runtime configuration** section, select **Run with a service account** to run the deduplicate query with a service account principal. Use this option for production queries.

Note

The service account you select must have the DeveloperManage and DeveloperWrite roles to create topics, schemas, and run Flink statements. For more information, see [Grant Role-Based Access](../operate-and-deploy/flink-rbac.html#flink-rbac).

  8. Click the **Show SQL** toggle to view the statement that the action will run.

For this example, the deduplication query depends on the `registertime` field, so you must modify the generated statement to use the `registertime` field as the field to sort on.

  9. Click **Open SQL editor** to modify the statement.

A Flink workspace opens with the generated statement in the cell.

  10. In the cell, replace `$rowtime` with `registertime` in the `ORDER BY` clause.

         CREATE TABLE `<your-environment>`.`<your-kafka-cluster>`.`users_deduplicate` (
                PRIMARY KEY (`user_id`) NOT ENFORCED
         ) DISTRIBUTED BY HASH(
                `user_id`
         ) WITH (
                'changelog.mode' = 'upsert',
                'value.format'='avro-registry',
                'key.format'='avro-registry'
         ) AS SELECT `user_id`, `registertime`, `gender`, `regionid` FROM (
                SELECT *,
                       ROW_NUMBER() OVER (PARTITION BY `user_id` ORDER BY registertime ASC) AS row_num
                FROM `<your-environment>`.`<your-kafka-cluster>`.`users`) WHERE row_num = 1;

  11. Click **Run** to execute the deduplication query.

The CREATE TABLE AS SELECT statement creates the `users_deduplicate` table and populates it with rows from the `users` table using a [deduplication query](../reference/queries/deduplication.html#flink-sql-deduplication).

  12. When the **Statement status** changes to **Running** , you can query the `users_deduplicate` table.

## Step 3: Inspect the output table¶

The statement generated by the Deduplicate Topic action created an output table named `users_deduplicate`. In this step, you query the output table to see the deduplicated rows.

* Run the following statement to inspect the `users_deduplicate` output table.

        SELECT * FROM users_deduplicate;

Your output should resemble:

        user_id            registertime gender regionid
        Thomas A. Anderson 1677260724   male   Region_4
        Trinity            1677260733   female Region_4
        Morpheus           1677260742   male   Region_8
        Dozer              1677260823   male   Region_1
        Agent Smith        1677260955   male   Region_0
        Persephone         1677260901   female Region_2
        Niobe              1677260921   female Region_3
        Zee                1677260922   female Region_5
